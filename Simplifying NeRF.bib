
@software{noauthor_automatic1111_2022,
	title = {{AUTOMATIC}1111 - Stable Diffusion Web {UI}},
	rights = {{AGPL}-3.0},
	url = {https://github.com/AUTOMATIC1111/stable-diffusion-webui},
	abstract = {Stable Diffusion web {UI}},
	urldate = {2023-10-16},
	date = {2022-08},
	note = {original-date: 2022-08-22T14:05:26Z},
}

@online{team_gradio_nodate,
	title = {Gradio},
	url = {https://gradio.app},
	abstract = {Build \& Share Delightful Machine Learning Apps},
	author = {Team, Gradio},
	urldate = {2023-10-16},
	langid = {german},
	file = {Snapshot:/Users/eduard.von-briesen/Zotero/storage/N2SXMK6R/www.gradio.app.html:text/html},
}

@inproceedings{wang_clip-nerf_2022,
	title = {{CLIP}-{NeRF}: Text-and-Image Driven Manipulation of Neural Radiance Fields},
	pages = {3835--3844},
	booktitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Wang, Can and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing},
	date = {2022-06},
	file = {Wang et al. - 2022 - CLIP-NeRF Text-and-Image Driven Manipulation of N.pdf:/Users/eduard.von-briesen/Zotero/storage/QSE9GGYZ/Wang et al. - 2022 - CLIP-NeRF Text-and-Image Driven Manipulation of N.pdf:application/pdf},
}

@misc{bar-tal_text2live_2022,
	title = {Text2LIVE: Text-Driven Layered Image and Video Editing},
	author = {Bar-Tal, Omer and Ofri-Amar, Dolev and Fridman, Rafail and Kasten, Yoni and Dekel, Tali},
	date = {2022},
	note = {\_eprint: 2204.02491},
	file = {Bar-Tal et al. - 2022 - Text2LIVE Text-Driven Layered Image and Video Edi.pdf:/Users/eduard.von-briesen/Zotero/storage/I3G8Z7US/Bar-Tal et al. - 2022 - Text2LIVE Text-Driven Layered Image and Video Edi.pdf:application/pdf},
}

@article{muller_instant_2022,
	title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
	volume = {41},
	url = {https://doi.org/10.1145/3528223.3530127},
	doi = {10.1145/3528223.3530127},
	pages = {102:1--102:15},
	number = {4},
	journaltitle = {{ACM} Trans. Graph.},
	author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
	date = {2022-07},
	note = {Place: New York, {NY}, {USA}
Publisher: {ACM}},
	file = {Müller et al. - 2022 - Instant Neural Graphics Primitives with a Multires.pdf:/Users/eduard.von-briesen/Zotero/storage/NP73B3FX/Müller et al. - 2022 - Instant Neural Graphics Primitives with a Multires.pdf:application/pdf},
}

@inproceedings{bao_sine_2023,
	title = {{SINE}: Semantic-driven Image-based {NeRF} Editing with Prior-guided Editing Field},
	booktitle = {The {IEEE}/{CVF} Computer Vision and Pattern Recognition Conference ({CVPR})},
	author = {Bao, Chong and Zhang, Yinda and Yang, Bangbang and Fan, Tianxing and Yang, Zesong and Bao, Hujun and Zhang, Guofeng and Cui, Zhaopeng},
	date = {2023},
	file = {Bao et al. - 2023 - SINE Semantic-driven Image-based NeRF Editing wit.pdf:/Users/eduard.von-briesen/Zotero/storage/WTEP74IW/Bao et al. - 2023 - SINE Semantic-driven Image-based NeRF Editing wit.pdf:application/pdf},
}

@misc{wu_palettenerf_2022,
	title = {{PaletteNeRF}: Palette-based Color Editing for {NeRFs}},
	author = {Wu, Qiling and Tan, Jianchao and Xu, Kun},
	date = {2022},
	note = {\_eprint: 2212.12871},
	file = {Wu et al. - 2022 - PaletteNeRF Palette-based Color Editing for NeRFs.pdf:/Users/eduard.von-briesen/Zotero/storage/B75YG3CP/Wu et al. - 2022 - PaletteNeRF Palette-based Color Editing for NeRFs.pdf:application/pdf},
}

@inproceedings{haque_instruct-nerf2nerf_2023,
	title = {Instruct-{NeRF}2NeRF: Editing 3D Scenes with Instructions},
	booktitle = {Proceedings of the {IEEE}/{CVF} International Conference on Computer Vision},
	author = {Haque, Ayaan and Tancik, Matthew and Efros, Alexei and Holynski, Aleksander and Kanazawa, Angjoo},
	date = {2023},
	file = {Haque et al. - 2023 - Instruct-NeRF2NeRF Editing 3D Scenes with Instruc.pdf:/Users/eduard.von-briesen/Zotero/storage/UABJT6NX/Haque et al. - 2023 - Instruct-NeRF2NeRF Editing 3D Scenes with Instruc.pdf:application/pdf},
}

@inproceedings{yuan_nerf-editing_2022,
	title = {{NeRF}-Editing: Geometry Editing of Neural Radiance Fields},
	pages = {18353--18364},
	booktitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Yuan, Yu-Jie and Sun, Yang-Tian and Lai, Yu-Kun and Ma, Yuewen and Jia, Rongfei and Gao, Lin},
	date = {2022-06},
	file = {Yuan et al. - 2022 - NeRF-Editing Geometry Editing of Neural Radiance .pdf:/Users/eduard.von-briesen/Zotero/storage/WXK4HSYZ/Yuan et al. - 2022 - NeRF-Editing Geometry Editing of Neural Radiance .pdf:application/pdf},
}

@inproceedings{tancik_nerfstudio_2023,
	title = {Nerfstudio: A Modular Framework for Neural Radiance Field Development},
	series = {{SIGGRAPH} '23},
	booktitle = {{ACM} {SIGGRAPH} 2023 Conference Proceedings},
	author = {Tancik, Matthew and Weber, Ethan and Ng, Evonne and Li, Ruilong and Yi, Brent and Kerr, Justin and Wang, Terrance and Kristoffersen, Alexander and Austin, Jake and Salahi, Kamyar and Ahuja, Abhik and {McAllister}, David and Kanazawa, Angjoo},
	date = {2023},
	file = {Tancik et al. - 2023 - Nerfstudio A Modular Framework for Neural Radianc.pdf:/Users/eduard.von-briesen/Zotero/storage/495RZA9X/Tancik et al. - 2023 - Nerfstudio A Modular Framework for Neural Radianc.pdf:application/pdf},
}

@inproceedings{laugwitz_construction_2008,
	location = {Berlin, Heidelberg},
	title = {Construction and Evaluation of a User Experience Questionnaire},
	isbn = {978-3-540-89350-9},
	doi = {10.1007/978-3-540-89350-9_6},
	series = {Lecture Notes in Computer Science},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practical relevance of items. Usability experts collected terms and statements on user experience and usability, including ‘hard’ as well as ‘soft’ aspects. These statements were consolidated and transformed into a first questionnaire version containing 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six factors Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and Novelty. Studies conducted for the original German questionnaire and an English version indicate a satisfactory level of reliability and construct validity.},
	pages = {63--76},
	booktitle = {{HCI} and Usability for Education and Work},
	publisher = {Springer},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	editor = {Holzinger, Andreas},
	date = {2008},
	langid = {english},
	keywords = {Perceived usability, Questionnaire, Software evaluation, Usability assessment, User experience, User satisfaction},
}
